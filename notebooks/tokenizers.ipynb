{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "982a8ccb-2ad0-4596-86d5-926c200d3520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, device\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import T5Tokenizer, AutoTokenizer, AutoModel, T5EncoderModel, XLNetModel\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.autonotebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b91109-2254-4733-841d-917a545b96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2)\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d4d5f-738a-404d-a25a-6ea3a449d303",
   "metadata": {},
   "source": [
    "## Plain old text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7c21a24-29c5-4485-bca6-c099b64eab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(company_name: str):\n",
    "    file_folder_path = f\"pdf/{company_name}\"\n",
    "    doc = [os.path.join(file_folder_path, file) for file in os.listdir(file_folder_path)][0]  # Only the first doc\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500,\n",
    "        chunk_overlap=200,\n",
    "        add_start_index=True\n",
    "    )\n",
    "\n",
    "    loader = UnstructuredFileLoader(doc, mode=\"single\", strategy=\"fast\")\n",
    "    chunks = loader.load_and_split(text_splitter)\n",
    "\n",
    "    content = [f\"Company: {company_name}. \" + chunk.page_content for chunk in chunks]\n",
    "    metadata = [chunk.metadata for chunk in chunks]\n",
    "\n",
    "    return content, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c88b7a25-d14b-4650-882d-f242c4738317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nezumikozo/Documents/workspace/rag-redis-demo/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "content, metadata = get_chunks(company_name=\"novo_nordisk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9db0a7f-3230-48c3-9f82-b0a52e6a7e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "260\n",
      "262\n",
      "265\n"
     ]
    }
   ],
   "source": [
    "for _idx, _content in enumerate(content):\n",
    "    if \"scope 1 emission\" in _content.lower():\n",
    "        print(_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b388f699-ca6e-4583-8b07-25278dbb7616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Company: novo_nordisk. 51,951\\n\\n42,138\\n\\n123.3%\\n\\n2020\\n\\n28,565\\n\\n42,138\\n\\n67.8%\\n\\nContents Introducing Novo Nordisk Strategic Aspirations Key risks Management Consolidated statements Additional information\\n\\nNote\\n\\n2022\\n\\n2021\\n\\nStatement of Environmental, Social and Governance (ESG) performance\\n\\nEnvironmental performance\\n\\nResources\\n\\nEnergy consumption for operations (1,000 GJ)\\n\\nShare of renewable power for production sites Water consumption for production sites (1,000 m3) Breaches of environmental regulatory limit values\\n\\nEmissions and waste Scope 1 emissions (1,000 tonnes CO2) Scope 2 emissions (1,000 tonnes CO2) Scope 3 emissions (1,000 tonnes CO2)1 Waste from production sites (tonnes)\\n\\n7.1\\n\\n7.1\\n\\n7.2\\n\\n7.3\\n\\n7.4\\n\\n7.4\\n\\n7.4\\n\\n7.5\\n\\n3,677\\n\\n100%\\n\\n3,918\\n\\n75\\n\\n76\\n\\n16\\n\\n2,041\\n\\n213,505\\n\\n3,387\\n\\n100%\\n\\n3,488\\n\\n12\\n\\n77\\n\\n16\\n\\nN/A\\n\\n180,806\\n\\nfor the year ended 31 December\\n\\nSocial performance\\n\\nPatients\\n\\nPatients reached with Novo Nordisk's Diabetes care products (estimate in millions) – Hereof reached via the Novo Nordisk Access to Insulin Commitment (estimate in millions)2 – Hereof children reached through the Changing Diabetes® in Children programme (cumulative) People & employees\\n\\n8.1\\n\\n8.1\\n\\n8.1\\n\\n36.3\\n\\n1.8\\n\\n41,033\\n\\n34.6\\n\\n1.7\\n\\n31,846\\n\\nEmployees\\n\\n8.2\\n\\n55,185\\n\\n48,478\\n\\nEmployee turnover Sustainable employer score3 Frequency of occupational accidents (number per million working hours)\\n\\n8.2\\n\\n8.3\\n\\n8.4\\n\\n8.2%\\n\\n85%\\n\\n1.5\\n\\n11.0%\\n\\n84%\\n\\n1.3\\n\\nGender in leadership positions (ratio men:women)\\n\\n8.5\\n\\n56:44\\n\\n57:43\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5e87df5-eb43-4116-b557-916fa15c2660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Company: novo_nordisk. In 2022, Scope 1 emissions decreased by 1% compared to 2021 due to an increase in usage of renewable energy sources as a result of two production facilities, in the US and France, having converted to using biogas. Scope 2 emissions were in line with 2021. In 2022, we have expanded our Scope 3 reporting to include all categories of emissions from the GHG protocol relevant to Novo Nordisk. The highest portion of Scope 3 emissions was in purchased goods and services and capital goods. These two categories together make up to 85% of the overall Scope 3 emissions.\\n\\n– Capital goods2\\n\\n– Fuel and energy related activities2\\n\\n– Upstream transportation and distribution2\\n\\n– Waste generated in operations2\\n\\n– Business travel\\n\\n– Employee commuting2\\n\\n477\\n\\n55\\n\\n123\\n\\n5\\n\\n55\\n\\n35\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\n– Downstream transportation and distribution2\\n\\n37\\n\\nN/A\\n\\n7.2 Water consumption for production sites\\n\\n– End-of-life treatment of sold products2\\n\\n3\\n\\nN/A\\n\\nTotal CO2 emissions\\n\\n2,133\\n\\nN/A\\n\\nIn 2022, production sites consumed 3,918 thousand cubic metres of water, an increase of 12% compared to 2021 due to higher production volumes and ramp-up activities within production sites.\\n\\n1. The calculation of Scope 3 emissions is substantially based on estimations\\n\\nand therefore inherently uncertain.\\n\\n2. Categories measured in CO2 equivalents (CO2e).'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[260]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70f2e0b-be72-419f-af88-bc0734f64b18",
   "metadata": {},
   "source": [
    "## Encoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf421bb7-647c-4250-8b3e-09e34af3a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph here\n",
    "## input & output\n",
    "## infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f05d75d8-757f-4c96-8aa4-d75026502c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".gitattributes: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 690/690 [00:00<00:00, 658kB/s]\n",
      "1_Pooling/config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:00<00:00, 204kB/s]\n",
      "README.md: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.99k/3.99k [00:00<00:00, 3.99MB/s]\n",
      "config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 548/548 [00:00<00:00, 545kB/s]\n",
      "config_sentence_transformers.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [00:00<00:00, 130kB/s]\n",
      "pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 265M/265M [02:15<00:00, 1.96MB/s]\n",
      "sentence_bert_config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 53.0/53.0 [00:00<00:00, 54.4kB/s]\n",
      "special_tokens_map.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 146kB/s]\n",
      "tokenizer.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 1.51MB/s]\n",
      "tokenizer_config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 547/547 [00:00<00:00, 865kB/s]\n",
      "vocab.txt: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 1.15MB/s]\n",
      "modules.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 229/229 [00:00<00:00, 247kB/s]\n"
     ]
    }
   ],
   "source": [
    "default_embedder = SentenceTransformer(\n",
    "    \"sentence-transformers/msmarco-distilbert-base-tas-b\", \n",
    "    cache_folder=\"cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b2d4dda8-6326-4a49-965f-c988acdcde3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_content = default_embedder.encode(content[251])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad869299-f08f-4e9e-a8ad-cb7e3a1aff1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c008bba6-dfa1-4d23-b73d-72d7f65b1e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2132133 ,  0.11719614,  0.22745958, -0.29696494,  0.16332254,\n",
       "        0.4249692 ,  0.2892638 , -0.5250201 ,  0.04183745, -0.41405323],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_content[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34689ef3-e6ae-4ece-835b-8bd8b6062167",
   "metadata": {},
   "source": [
    "### Why do we encode content in embedded space?\n",
    "\n",
    "- Semantic search? Do we need it?!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce045f9e-3fd0-426c-8463-3c826b16e87c",
   "metadata": {},
   "source": [
    "### 1. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fdcebdfc-1523-48a8-a095-00b4d4a14a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tokens(sentence: str, tokenizer):\n",
    "    \n",
    "    inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    print(\"Number of tokens:\", len(inputs.input_ids[0]))\n",
    "        \n",
    "    for input_id in inputs.input_ids[0]:\n",
    "        print(input_id, \"->\", tokenizer.decode(input_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7a552b4-7d09-4e54-b98f-32cd715769cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-tas-b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bec848c0-7432-4ed4-ac5e-8c9b940dbd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 375\n",
      "tensor(101) -> [CLS]\n",
      "tensor(2194) -> company\n",
      "tensor(1024) -> :\n",
      "tensor(24576) -> novo\n",
      "tensor(1035) -> _\n",
      "tensor(13926) -> nord\n",
      "tensor(20573) -> ##isk\n",
      "tensor(1012) -> .\n",
      "tensor(4868) -> 51\n",
      "tensor(1010) -> ,\n",
      "tensor(5345) -> 95\n",
      "tensor(2487) -> ##1\n",
      "tensor(4413) -> 42\n",
      "tensor(1010) -> ,\n",
      "tensor(15028) -> 138\n",
      "tensor(13138) -> 123\n",
      "tensor(1012) -> .\n",
      "tensor(1017) -> 3\n",
      "tensor(1003) -> %\n",
      "tensor(12609) -> 2020\n",
      "tensor(2654) -> 28\n",
      "tensor(1010) -> ,\n",
      "tensor(5179) -> 56\n",
      "tensor(2629) -> ##5\n",
      "tensor(4413) -> 42\n",
      "tensor(1010) -> ,\n",
      "tensor(15028) -> 138\n",
      "tensor(6163) -> 67\n",
      "tensor(1012) -> .\n",
      "tensor(1022) -> 8\n",
      "tensor(1003) -> %\n",
      "tensor(8417) -> contents\n",
      "tensor(10449) -> introducing\n",
      "tensor(24576) -> novo\n",
      "tensor(13926) -> nord\n",
      "tensor(20573) -> ##isk\n",
      "tensor(6143) -> strategic\n",
      "tensor(22877) -> aspirations\n",
      "tensor(3145) -> key\n",
      "tensor(10831) -> risks\n",
      "tensor(2968) -> management\n",
      "tensor(10495) -> consolidated\n",
      "tensor(8635) -> statements\n",
      "tensor(3176) -> additional\n",
      "tensor(2592) -> information\n",
      "tensor(3602) -> note\n",
      "tensor(16798) -> 202\n",
      "tensor(2475) -> ##2\n",
      "tensor(25682) -> 2021\n",
      "tensor(4861) -> statement\n",
      "tensor(1997) -> of\n",
      "tensor(4483) -> environmental\n",
      "tensor(1010) -> ,\n",
      "tensor(2591) -> social\n",
      "tensor(1998) -> and\n",
      "tensor(10615) -> governance\n",
      "tensor(1006) -> (\n",
      "tensor(9686) -> es\n",
      "tensor(2290) -> ##g\n",
      "tensor(1007) -> )\n",
      "tensor(2836) -> performance\n",
      "tensor(4483) -> environmental\n",
      "tensor(2836) -> performance\n",
      "tensor(4219) -> resources\n",
      "tensor(2943) -> energy\n",
      "tensor(8381) -> consumption\n",
      "tensor(2005) -> for\n",
      "tensor(3136) -> operations\n",
      "tensor(1006) -> (\n",
      "tensor(1015) -> 1\n",
      "tensor(1010) -> ,\n",
      "tensor(2199) -> 000\n",
      "tensor(1043) -> g\n",
      "tensor(3501) -> ##j\n",
      "tensor(1007) -> )\n",
      "tensor(3745) -> share\n",
      "tensor(1997) -> of\n",
      "tensor(13918) -> renewable\n",
      "tensor(2373) -> power\n",
      "tensor(2005) -> for\n",
      "tensor(2537) -> production\n",
      "tensor(4573) -> sites\n",
      "tensor(2300) -> water\n",
      "tensor(8381) -> consumption\n",
      "tensor(2005) -> for\n",
      "tensor(2537) -> production\n",
      "tensor(4573) -> sites\n",
      "tensor(1006) -> (\n",
      "tensor(1015) -> 1\n",
      "tensor(1010) -> ,\n",
      "tensor(2199) -> 000\n",
      "tensor(29061) -> m3\n",
      "tensor(1007) -> )\n",
      "tensor(12510) -> breach\n",
      "tensor(2229) -> ##es\n",
      "tensor(1997) -> of\n",
      "tensor(4483) -> environmental\n",
      "tensor(10738) -> regulatory\n",
      "tensor(5787) -> limit\n",
      "tensor(5300) -> values\n",
      "tensor(11768) -> emissions\n",
      "tensor(1998) -> and\n",
      "tensor(5949) -> waste\n",
      "tensor(9531) -> scope\n",
      "tensor(1015) -> 1\n",
      "tensor(11768) -> emissions\n",
      "tensor(1006) -> (\n",
      "tensor(1015) -> 1\n",
      "tensor(1010) -> ,\n",
      "tensor(2199) -> 000\n",
      "tensor(11000) -> tonnes\n",
      "tensor(2522) -> co\n",
      "tensor(2475) -> ##2\n",
      "tensor(1007) -> )\n",
      "tensor(9531) -> scope\n",
      "tensor(1016) -> 2\n",
      "tensor(11768) -> emissions\n",
      "tensor(1006) -> (\n",
      "tensor(1015) -> 1\n",
      "tensor(1010) -> ,\n",
      "tensor(2199) -> 000\n",
      "tensor(11000) -> tonnes\n",
      "tensor(2522) -> co\n",
      "tensor(2475) -> ##2\n",
      "tensor(1007) -> )\n",
      "tensor(9531) -> scope\n",
      "tensor(1017) -> 3\n",
      "tensor(11768) -> emissions\n",
      "tensor(1006) -> (\n",
      "tensor(1015) -> 1\n",
      "tensor(1010) -> ,\n",
      "tensor(2199) -> 000\n",
      "tensor(11000) -> tonnes\n",
      "tensor(2522) -> co\n",
      "tensor(2475) -> ##2\n",
      "tensor(1007) -> )\n",
      "tensor(1015) -> 1\n",
      "tensor(5949) -> waste\n",
      "tensor(2013) -> from\n",
      "tensor(2537) -> production\n",
      "tensor(4573) -> sites\n",
      "tensor(1006) -> (\n",
      "tensor(11000) -> tonnes\n",
      "tensor(1007) -> )\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1015) -> 1\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1015) -> 1\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1016) -> 2\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1017) -> 3\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1018) -> 4\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1018) -> 4\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1018) -> 4\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1019) -> 5\n",
      "tensor(1017) -> 3\n",
      "tensor(1010) -> ,\n",
      "tensor(6163) -> 67\n",
      "tensor(2581) -> ##7\n",
      "tensor(2531) -> 100\n",
      "tensor(1003) -> %\n",
      "tensor(1017) -> 3\n",
      "tensor(1010) -> ,\n",
      "tensor(6205) -> 91\n",
      "tensor(2620) -> ##8\n",
      "tensor(4293) -> 75\n",
      "tensor(6146) -> 76\n",
      "tensor(2385) -> 16\n",
      "tensor(1016) -> 2\n",
      "tensor(1010) -> ,\n",
      "tensor(5840) -> 04\n",
      "tensor(2487) -> ##1\n",
      "tensor(19883) -> 213\n",
      "tensor(1010) -> ,\n",
      "tensor(28952) -> 505\n",
      "tensor(1017) -> 3\n",
      "tensor(1010) -> ,\n",
      "tensor(4229) -> 38\n",
      "tensor(2581) -> ##7\n",
      "tensor(2531) -> 100\n",
      "tensor(1003) -> %\n",
      "tensor(1017) -> 3\n",
      "tensor(1010) -> ,\n",
      "tensor(4466) -> 48\n",
      "tensor(2620) -> ##8\n",
      "tensor(2260) -> 12\n",
      "tensor(6255) -> 77\n",
      "tensor(2385) -> 16\n",
      "tensor(1050) -> n\n",
      "tensor(1013) -> /\n",
      "tensor(1037) -> a\n",
      "tensor(8380) -> 180\n",
      "tensor(1010) -> ,\n",
      "tensor(3770) -> 80\n",
      "tensor(2575) -> ##6\n",
      "tensor(2005) -> for\n",
      "tensor(1996) -> the\n",
      "tensor(2095) -> year\n",
      "tensor(3092) -> ended\n",
      "tensor(2861) -> 31\n",
      "tensor(2285) -> december\n",
      "tensor(2591) -> social\n",
      "tensor(2836) -> performance\n",
      "tensor(5022) -> patients\n",
      "tensor(5022) -> patients\n",
      "tensor(2584) -> reached\n",
      "tensor(2007) -> with\n",
      "tensor(24576) -> novo\n",
      "tensor(13926) -> nord\n",
      "tensor(20573) -> ##isk\n",
      "tensor(1005) -> '\n",
      "tensor(1055) -> s\n",
      "tensor(14671) -> diabetes\n",
      "tensor(2729) -> care\n",
      "tensor(3688) -> products\n",
      "tensor(1006) -> (\n",
      "tensor(10197) -> estimate\n",
      "tensor(1999) -> in\n",
      "tensor(8817) -> millions\n",
      "tensor(1007) -> )\n",
      "tensor(1516) -> –\n",
      "tensor(2182) -> here\n",
      "tensor(11253) -> ##of\n",
      "tensor(2584) -> reached\n",
      "tensor(3081) -> via\n",
      "tensor(1996) -> the\n",
      "tensor(24576) -> novo\n",
      "tensor(13926) -> nord\n",
      "tensor(20573) -> ##isk\n",
      "tensor(3229) -> access\n",
      "tensor(2000) -> to\n",
      "tensor(22597) -> insulin\n",
      "tensor(8426) -> commitment\n",
      "tensor(1006) -> (\n",
      "tensor(10197) -> estimate\n",
      "tensor(1999) -> in\n",
      "tensor(8817) -> millions\n",
      "tensor(1007) -> )\n",
      "tensor(1016) -> 2\n",
      "tensor(1516) -> –\n",
      "tensor(2182) -> here\n",
      "tensor(11253) -> ##of\n",
      "tensor(2336) -> children\n",
      "tensor(2584) -> reached\n",
      "tensor(2083) -> through\n",
      "tensor(1996) -> the\n",
      "tensor(5278) -> changing\n",
      "tensor(14671) -> diabetes\n",
      "tensor(29656) -> ##®\n",
      "tensor(1999) -> in\n",
      "tensor(2336) -> children\n",
      "tensor(4746) -> programme\n",
      "tensor(1006) -> (\n",
      "tensor(23260) -> cumulative\n",
      "tensor(1007) -> )\n",
      "tensor(2111) -> people\n",
      "tensor(1004) -> &\n",
      "tensor(5126) -> employees\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1015) -> 1\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1015) -> 1\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1015) -> 1\n",
      "tensor(4029) -> 36\n",
      "tensor(1012) -> .\n",
      "tensor(1017) -> 3\n",
      "tensor(1015) -> 1\n",
      "tensor(1012) -> .\n",
      "tensor(1022) -> 8\n",
      "tensor(4601) -> 41\n",
      "tensor(1010) -> ,\n",
      "tensor(6021) -> 03\n",
      "tensor(2509) -> ##3\n",
      "tensor(4090) -> 34\n",
      "tensor(1012) -> .\n",
      "tensor(1020) -> 6\n",
      "tensor(1015) -> 1\n",
      "tensor(1012) -> .\n",
      "tensor(1021) -> 7\n",
      "tensor(2861) -> 31\n",
      "tensor(1010) -> ,\n",
      "tensor(6391) -> 84\n",
      "tensor(2575) -> ##6\n",
      "tensor(5126) -> employees\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1016) -> 2\n",
      "tensor(4583) -> 55\n",
      "tensor(1010) -> ,\n",
      "tensor(15376) -> 185\n",
      "tensor(4466) -> 48\n",
      "tensor(1010) -> ,\n",
      "tensor(4700) -> 47\n",
      "tensor(2620) -> ##8\n",
      "tensor(7904) -> employee\n",
      "tensor(20991) -> turnover\n",
      "tensor(9084) -> sustainable\n",
      "tensor(11194) -> employer\n",
      "tensor(3556) -> score\n",
      "tensor(2509) -> ##3\n",
      "tensor(6075) -> frequency\n",
      "tensor(1997) -> of\n",
      "tensor(16928) -> occupational\n",
      "tensor(13436) -> accidents\n",
      "tensor(1006) -> (\n",
      "tensor(2193) -> number\n",
      "tensor(2566) -> per\n",
      "tensor(2454) -> million\n",
      "tensor(2551) -> working\n",
      "tensor(2847) -> hours\n",
      "tensor(1007) -> )\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1016) -> 2\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1017) -> 3\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1018) -> 4\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1016) -> 2\n",
      "tensor(1003) -> %\n",
      "tensor(5594) -> 85\n",
      "tensor(1003) -> %\n",
      "tensor(1015) -> 1\n",
      "tensor(1012) -> .\n",
      "tensor(1019) -> 5\n",
      "tensor(2340) -> 11\n",
      "tensor(1012) -> .\n",
      "tensor(1014) -> 0\n",
      "tensor(1003) -> %\n",
      "tensor(6391) -> 84\n",
      "tensor(1003) -> %\n",
      "tensor(1015) -> 1\n",
      "tensor(1012) -> .\n",
      "tensor(1017) -> 3\n",
      "tensor(5907) -> gender\n",
      "tensor(1999) -> in\n",
      "tensor(4105) -> leadership\n",
      "tensor(4460) -> positions\n",
      "tensor(1006) -> (\n",
      "tensor(6463) -> ratio\n",
      "tensor(2273) -> men\n",
      "tensor(1024) -> :\n",
      "tensor(2308) -> women\n",
      "tensor(1007) -> )\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1019) -> 5\n",
      "tensor(5179) -> 56\n",
      "tensor(1024) -> :\n",
      "tensor(4008) -> 44\n",
      "tensor(5401) -> 57\n",
      "tensor(1024) -> :\n",
      "tensor(4724) -> 43\n",
      "tensor(102) -> [SEP]\n"
     ]
    }
   ],
   "source": [
    "show_tokens(sentence=content[251], tokenizer=default_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe2b5cd-c6fb-42c7-b292-bfbce1e3a227",
   "metadata": {},
   "source": [
    "### 2. Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aea0132a-3781-41a3-876b-48bdb0cd464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    # First element of model_output contains all token embeddings\n",
    "    token_embeddings = model_output[0]  \n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61ca7b44-bbe8-415e-9e89-6670a796ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLS Pooling - Take output from first token\n",
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d93f5e15-de41-4d71-8af4-9565c11e726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_device(batch, target_device: device):\n",
    "    \"\"\"\n",
    "    send a pytorch batch to a device (CPU/GPU)\n",
    "    \"\"\"\n",
    "    for key in batch:\n",
    "        if isinstance(batch[key], Tensor):\n",
    "            batch[key] = batch[key].to(target_device)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fdadd8fe-cef5-4c15-a648-85ccc3ce5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batched_embeddings(sentences: List[str], batch_size: int, tokenizer, model, device=\"cpu\"):\n",
    "    \n",
    "    all_embeddings = []\n",
    "    \n",
    "    for start_index in trange(0, len(sentences), batch_size):\n",
    "        # 1. Tokenize sentences\n",
    "        batch = sentences[start_index:start_index+batch_size]\n",
    "        encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "        \n",
    "        encoded_input = batch_to_device(encoded_input, device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # 2. Compute token embeddings -> Same toke might have different embeddings due to context.\n",
    "            model_output = model(**encoded_input)\n",
    "            print(\"Shape of embedded tokens:\", model_output.last_hidden_state.shape)\n",
    "\n",
    "            # 3. Perform pooling\n",
    "            # Option 1: Mean pooling\n",
    "            # embeddings = mean_pooling(model_output, encoded_input.attention_mask)\n",
    "            # Option 2: CLS pooling\n",
    "            embeddings = cls_pooling(model_output)\n",
    "            embeddings = embeddings.detach()\n",
    "            \n",
    "            all_embeddings.extend(embeddings)\n",
    "    \n",
    "    all_embeddings = torch.stack(all_embeddings)\n",
    "    \n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "37dbf3fd-45c1-404b-b125-70cb4f4dc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_model = AutoModel.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-tas-b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7d5193ac-80c4-4c4f-b950-dd28b25fd617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedded tokens: torch.Size([1, 375, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batched_embeddings = get_batched_embeddings(\n",
    "    sentences=[content[251]],\n",
    "    batch_size=1,\n",
    "    tokenizer=default_tokenizer,\n",
    "    model=default_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ff9a208c-4a76-4377-abe4-00a4099f3c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a0370e13-c27d-4a0a-96d0-71071120760e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2132133 ,  0.11719614,  0.22745958, -0.29696494,  0.16332254,\n",
       "        0.4249692 ,  0.2892638 , -0.5250201 ,  0.04183745, -0.41405323],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_embeddings[0].numpy()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b114f31f-eb1c-4832-b431-971f230c1ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.00]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.cos_sim(encoded_content, batched_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa37b0-ee04-42db-93dc-088858755bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-redis-demo",
   "language": "python",
   "name": "rag-redis-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
