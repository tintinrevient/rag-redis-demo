{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a708f6-67c3-4191-8602-dc0666d26b9f",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "982a8ccb-2ad0-4596-86d5-926c200d3520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nezumikozo/Documents/workspace/rag-redis-demo/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, device\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.autonotebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b91109-2254-4733-841d-917a545b96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2)\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e49aef-bf31-42f3-bb30-07a662325d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "@register_cell_magic\n",
    "def background_color(color, cell=None):\n",
    "    script = (\n",
    "        \"var cell = this.closest('.jp-CodeCell');\"\n",
    "        \"var editor = cell.querySelector('.jp-Editor');\"\n",
    "        \"editor.style.background='{}';\"\n",
    "        \"this.parentNode.removeChild(this)\"\n",
    "    ).format(color)\n",
    "\n",
    "    display(HTML('<img src onerror=\"{}\">'.format(script)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d4d5f-738a-404d-a25a-6ea3a449d303",
   "metadata": {},
   "source": [
    "## Plain old text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c21a24-29c5-4485-bca6-c099b64eab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(company_name: str):\n",
    "    file_folder_path = f\"pdf/{company_name}\"\n",
    "    doc = [os.path.join(file_folder_path, file) for file in os.listdir(file_folder_path)][0]  # Only the first doc\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500,\n",
    "        chunk_overlap=200,\n",
    "        add_start_index=True\n",
    "    )\n",
    "\n",
    "    loader = UnstructuredFileLoader(doc, mode=\"single\", strategy=\"fast\")\n",
    "    chunks = loader.load_and_split(text_splitter)\n",
    "\n",
    "    content = [f\"Company: {company_name}. \" + chunk.page_content for chunk in chunks]\n",
    "    metadata = [chunk.metadata for chunk in chunks]\n",
    "\n",
    "    return content, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c88b7a25-d14b-4650-882d-f242c4738317",
   "metadata": {},
   "outputs": [],
   "source": [
    "content, metadata = get_chunks(company_name=\"novo_nordisk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9db0a7f-3230-48c3-9f82-b0a52e6a7e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "260\n",
      "262\n",
      "265\n"
     ]
    }
   ],
   "source": [
    "for _idx, _content in enumerate(content):\n",
    "    if \"scope 1 emission\" in _content.lower():\n",
    "        print(_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b388f699-ca6e-4583-8b07-25278dbb7616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Company: novo_nordisk. 51,951\\n\\n42,138\\n\\n123.3%\\n\\n2020\\n\\n28,565\\n\\n42,138\\n\\n67.8%\\n\\nContents Introducing Novo Nordisk Strategic Aspirations Key risks Management Consolidated statements Additional information\\n\\nNote\\n\\n2022\\n\\n2021\\n\\nStatement of Environmental, Social and Governance (ESG) performance\\n\\nEnvironmental performance\\n\\nResources\\n\\nEnergy consumption for operations (1,000 GJ)\\n\\nShare of renewable power for production sites Water consumption for production sites (1,000 m3) Breaches of environmental regulatory limit values\\n\\nEmissions and waste Scope 1 emissions (1,000 tonnes CO2) Scope 2 emissions (1,000 tonnes CO2) Scope 3 emissions (1,000 tonnes CO2)1 Waste from production sites (tonnes)\\n\\n7.1\\n\\n7.1\\n\\n7.2\\n\\n7.3\\n\\n7.4\\n\\n7.4\\n\\n7.4\\n\\n7.5\\n\\n3,677\\n\\n100%\\n\\n3,918\\n\\n75\\n\\n76\\n\\n16\\n\\n2,041\\n\\n213,505\\n\\n3,387\\n\\n100%\\n\\n3,488\\n\\n12\\n\\n77\\n\\n16\\n\\nN/A\\n\\n180,806\\n\\nfor the year ended 31 December\\n\\nSocial performance\\n\\nPatients\\n\\nPatients reached with Novo Nordisk's Diabetes care products (estimate in millions) – Hereof reached via the Novo Nordisk Access to Insulin Commitment (estimate in millions)2 – Hereof children reached through the Changing Diabetes® in Children programme (cumulative) People & employees\\n\\n8.1\\n\\n8.1\\n\\n8.1\\n\\n36.3\\n\\n1.8\\n\\n41,033\\n\\n34.6\\n\\n1.7\\n\\n31,846\\n\\nEmployees\\n\\n8.2\\n\\n55,185\\n\\n48,478\\n\\nEmployee turnover Sustainable employer score3 Frequency of occupational accidents (number per million working hours)\\n\\n8.2\\n\\n8.3\\n\\n8.4\\n\\n8.2%\\n\\n85%\\n\\n1.5\\n\\n11.0%\\n\\n84%\\n\\n1.3\\n\\nGender in leadership positions (ratio men:women)\\n\\n8.5\\n\\n56:44\\n\\n57:43\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e87df5-eb43-4116-b557-916fa15c2660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Company: novo_nordisk. In 2022, Scope 1 emissions decreased by 1% compared to 2021 due to an increase in usage of renewable energy sources as a result of two production facilities, in the US and France, having converted to using biogas. Scope 2 emissions were in line with 2021. In 2022, we have expanded our Scope 3 reporting to include all categories of emissions from the GHG protocol relevant to Novo Nordisk. The highest portion of Scope 3 emissions was in purchased goods and services and capital goods. These two categories together make up to 85% of the overall Scope 3 emissions.\\n\\n– Capital goods2\\n\\n– Fuel and energy related activities2\\n\\n– Upstream transportation and distribution2\\n\\n– Waste generated in operations2\\n\\n– Business travel\\n\\n– Employee commuting2\\n\\n477\\n\\n55\\n\\n123\\n\\n5\\n\\n55\\n\\n35\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\n– Downstream transportation and distribution2\\n\\n37\\n\\nN/A\\n\\n7.2 Water consumption for production sites\\n\\n– End-of-life treatment of sold products2\\n\\n3\\n\\nN/A\\n\\nTotal CO2 emissions\\n\\n2,133\\n\\nN/A\\n\\nIn 2022, production sites consumed 3,918 thousand cubic metres of water, an increase of 12% compared to 2021 due to higher production volumes and ramp-up activities within production sites.\\n\\n1. The calculation of Scope 3 emissions is substantially based on estimations\\n\\nand therefore inherently uncertain.\\n\\n2. Categories measured in CO2 equivalents (CO2e).'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[260]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70f2e0b-be72-419f-af88-bc0734f64b18",
   "metadata": {},
   "source": [
    "## Encoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f05d75d8-757f-4c96-8aa4-d75026502c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_embedder = SentenceTransformer(\n",
    "    \"sentence-transformers/msmarco-distilbert-base-tas-b\", \n",
    "    cache_folder=\"cache\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2d4dda8-6326-4a49-965f-c988acdcde3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_content = default_embedder.encode(content[251])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad869299-f08f-4e9e-a8ad-cb7e3a1aff1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c008bba6-dfa1-4d23-b73d-72d7f65b1e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2132133 ,  0.11719614,  0.22745958, -0.29696494,  0.16332254,\n",
       "        0.4249692 ,  0.2892638 , -0.5250201 ,  0.04183745, -0.41405323],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_content[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee5c257-f875-40fd-87ee-3f8b49000899",
   "metadata": {},
   "source": [
    "<div style=\"background-color: honeydew\">\n",
    "\n",
    "## Why do we encode content in embedded space?\n",
    "- Semantic search! Instead of searching by the face value of the exact words, embedded space can encode meanings, so we can see the forest for the trees.\n",
    "- But do we need it? In which scenarios? Does number fit into this scenario?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578b77ec-ccd9-4273-b80e-ab440a4b6f48",
   "metadata": {},
   "source": [
    "## What is an encoder composed of?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6ccb78-1557-4264-9a12-9d9d769239dd",
   "metadata": {},
   "source": [
    "<img src=\"pix/embedding.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce045f9e-3fd0-426c-8463-3c826b16e87c",
   "metadata": {},
   "source": [
    "### Component 1 - Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdcebdfc-1523-48a8-a095-00b4d4a14a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tokens(sentence: str, tokenizer):\n",
    "    \n",
    "    inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    print(\"Number of tokens:\", len(inputs.input_ids[0]))\n",
    "        \n",
    "    for input_id in inputs.input_ids[0]:\n",
    "        print(input_id, \"->\", tokenizer.decode(input_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7a552b4-7d09-4e54-b98f-32cd715769cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-tas-b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bec848c0-7432-4ed4-ac5e-8c9b940dbd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 375\n",
      "tensor(101) -> [CLS]\n",
      "tensor(2194) -> company\n",
      "tensor(1024) -> :\n",
      "tensor(24576) -> novo\n",
      "tensor(1035) -> _\n",
      "tensor(13926) -> nord\n",
      "tensor(20573) -> ##isk\n",
      "tensor(1012) -> .\n",
      "tensor(4868) -> 51\n",
      "tensor(1010) -> ,\n",
      "tensor(5345) -> 95\n",
      "tensor(2487) -> ##1\n",
      "tensor(4413) -> 42\n",
      "tensor(1010) -> ,\n",
      "tensor(15028) -> 138\n",
      "tensor(13138) -> 123\n",
      "tensor(1012) -> .\n",
      "tensor(1017) -> 3\n",
      "tensor(1003) -> %\n",
      "tensor(12609) -> 2020\n",
      "tensor(2654) -> 28\n",
      "tensor(1010) -> ,\n",
      "tensor(5179) -> 56\n",
      "tensor(2629) -> ##5\n",
      "tensor(4413) -> 42\n",
      "tensor(1010) -> ,\n",
      "tensor(15028) -> 138\n",
      "tensor(6163) -> 67\n",
      "tensor(1012) -> .\n",
      "tensor(1022) -> 8\n",
      "tensor(1003) -> %\n",
      "tensor(8417) -> contents\n",
      "tensor(10449) -> introducing\n",
      "tensor(24576) -> novo\n",
      "tensor(13926) -> nord\n",
      "tensor(20573) -> ##isk\n",
      "tensor(6143) -> strategic\n",
      "tensor(22877) -> aspirations\n",
      "tensor(3145) -> key\n",
      "tensor(10831) -> risks\n",
      "tensor(2968) -> management\n",
      "tensor(10495) -> consolidated\n",
      "tensor(8635) -> statements\n",
      "tensor(3176) -> additional\n",
      "tensor(2592) -> information\n",
      "tensor(3602) -> note\n",
      "tensor(16798) -> 202\n",
      "tensor(2475) -> ##2\n",
      "tensor(25682) -> 2021\n",
      "tensor(4861) -> statement\n",
      "tensor(1997) -> of\n",
      "tensor(4483) -> environmental\n",
      "tensor(1010) -> ,\n",
      "tensor(2591) -> social\n",
      "tensor(1998) -> and\n",
      "tensor(10615) -> governance\n",
      "tensor(1006) -> (\n",
      "tensor(9686) -> es\n",
      "tensor(2290) -> ##g\n",
      "tensor(1007) -> )\n",
      "tensor(2836) -> performance\n",
      "tensor(4483) -> environmental\n",
      "tensor(2836) -> performance\n",
      "tensor(4219) -> resources\n",
      "tensor(2943) -> energy\n",
      "tensor(8381) -> consumption\n",
      "tensor(2005) -> for\n",
      "tensor(3136) -> operations\n",
      "tensor(1006) -> (\n",
      "tensor(1015) -> 1\n",
      "tensor(1010) -> ,\n",
      "tensor(2199) -> 000\n",
      "tensor(1043) -> g\n",
      "tensor(3501) -> ##j\n",
      "tensor(1007) -> )\n",
      "tensor(3745) -> share\n",
      "tensor(1997) -> of\n",
      "tensor(13918) -> renewable\n",
      "tensor(2373) -> power\n",
      "tensor(2005) -> for\n",
      "tensor(2537) -> production\n",
      "tensor(4573) -> sites\n",
      "tensor(2300) -> water\n",
      "tensor(8381) -> consumption\n",
      "tensor(2005) -> for\n",
      "tensor(2537) -> production\n",
      "tensor(4573) -> sites\n",
      "tensor(1006) -> (\n",
      "tensor(1015) -> 1\n",
      "tensor(1010) -> ,\n",
      "tensor(2199) -> 000\n",
      "tensor(29061) -> m3\n",
      "tensor(1007) -> )\n",
      "tensor(12510) -> breach\n",
      "tensor(2229) -> ##es\n",
      "tensor(1997) -> of\n",
      "tensor(4483) -> environmental\n",
      "tensor(10738) -> regulatory\n",
      "tensor(5787) -> limit\n",
      "tensor(5300) -> values\n",
      "tensor(11768) -> emissions\n",
      "tensor(1998) -> and\n",
      "tensor(5949) -> waste\n",
      "tensor(9531) -> scope\n",
      "tensor(1015) -> 1\n",
      "tensor(11768) -> emissions\n",
      "tensor(1006) -> (\n",
      "tensor(1015) -> 1\n",
      "tensor(1010) -> ,\n",
      "tensor(2199) -> 000\n",
      "tensor(11000) -> tonnes\n",
      "tensor(2522) -> co\n",
      "tensor(2475) -> ##2\n",
      "tensor(1007) -> )\n",
      "tensor(9531) -> scope\n",
      "tensor(1016) -> 2\n",
      "tensor(11768) -> emissions\n",
      "tensor(1006) -> (\n",
      "tensor(1015) -> 1\n",
      "tensor(1010) -> ,\n",
      "tensor(2199) -> 000\n",
      "tensor(11000) -> tonnes\n",
      "tensor(2522) -> co\n",
      "tensor(2475) -> ##2\n",
      "tensor(1007) -> )\n",
      "tensor(9531) -> scope\n",
      "tensor(1017) -> 3\n",
      "tensor(11768) -> emissions\n",
      "tensor(1006) -> (\n",
      "tensor(1015) -> 1\n",
      "tensor(1010) -> ,\n",
      "tensor(2199) -> 000\n",
      "tensor(11000) -> tonnes\n",
      "tensor(2522) -> co\n",
      "tensor(2475) -> ##2\n",
      "tensor(1007) -> )\n",
      "tensor(1015) -> 1\n",
      "tensor(5949) -> waste\n",
      "tensor(2013) -> from\n",
      "tensor(2537) -> production\n",
      "tensor(4573) -> sites\n",
      "tensor(1006) -> (\n",
      "tensor(11000) -> tonnes\n",
      "tensor(1007) -> )\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1015) -> 1\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1015) -> 1\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1016) -> 2\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1017) -> 3\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1018) -> 4\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1018) -> 4\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1018) -> 4\n",
      "tensor(1021) -> 7\n",
      "tensor(1012) -> .\n",
      "tensor(1019) -> 5\n",
      "tensor(1017) -> 3\n",
      "tensor(1010) -> ,\n",
      "tensor(6163) -> 67\n",
      "tensor(2581) -> ##7\n",
      "tensor(2531) -> 100\n",
      "tensor(1003) -> %\n",
      "tensor(1017) -> 3\n",
      "tensor(1010) -> ,\n",
      "tensor(6205) -> 91\n",
      "tensor(2620) -> ##8\n",
      "tensor(4293) -> 75\n",
      "tensor(6146) -> 76\n",
      "tensor(2385) -> 16\n",
      "tensor(1016) -> 2\n",
      "tensor(1010) -> ,\n",
      "tensor(5840) -> 04\n",
      "tensor(2487) -> ##1\n",
      "tensor(19883) -> 213\n",
      "tensor(1010) -> ,\n",
      "tensor(28952) -> 505\n",
      "tensor(1017) -> 3\n",
      "tensor(1010) -> ,\n",
      "tensor(4229) -> 38\n",
      "tensor(2581) -> ##7\n",
      "tensor(2531) -> 100\n",
      "tensor(1003) -> %\n",
      "tensor(1017) -> 3\n",
      "tensor(1010) -> ,\n",
      "tensor(4466) -> 48\n",
      "tensor(2620) -> ##8\n",
      "tensor(2260) -> 12\n",
      "tensor(6255) -> 77\n",
      "tensor(2385) -> 16\n",
      "tensor(1050) -> n\n",
      "tensor(1013) -> /\n",
      "tensor(1037) -> a\n",
      "tensor(8380) -> 180\n",
      "tensor(1010) -> ,\n",
      "tensor(3770) -> 80\n",
      "tensor(2575) -> ##6\n",
      "tensor(2005) -> for\n",
      "tensor(1996) -> the\n",
      "tensor(2095) -> year\n",
      "tensor(3092) -> ended\n",
      "tensor(2861) -> 31\n",
      "tensor(2285) -> december\n",
      "tensor(2591) -> social\n",
      "tensor(2836) -> performance\n",
      "tensor(5022) -> patients\n",
      "tensor(5022) -> patients\n",
      "tensor(2584) -> reached\n",
      "tensor(2007) -> with\n",
      "tensor(24576) -> novo\n",
      "tensor(13926) -> nord\n",
      "tensor(20573) -> ##isk\n",
      "tensor(1005) -> '\n",
      "tensor(1055) -> s\n",
      "tensor(14671) -> diabetes\n",
      "tensor(2729) -> care\n",
      "tensor(3688) -> products\n",
      "tensor(1006) -> (\n",
      "tensor(10197) -> estimate\n",
      "tensor(1999) -> in\n",
      "tensor(8817) -> millions\n",
      "tensor(1007) -> )\n",
      "tensor(1516) -> –\n",
      "tensor(2182) -> here\n",
      "tensor(11253) -> ##of\n",
      "tensor(2584) -> reached\n",
      "tensor(3081) -> via\n",
      "tensor(1996) -> the\n",
      "tensor(24576) -> novo\n",
      "tensor(13926) -> nord\n",
      "tensor(20573) -> ##isk\n",
      "tensor(3229) -> access\n",
      "tensor(2000) -> to\n",
      "tensor(22597) -> insulin\n",
      "tensor(8426) -> commitment\n",
      "tensor(1006) -> (\n",
      "tensor(10197) -> estimate\n",
      "tensor(1999) -> in\n",
      "tensor(8817) -> millions\n",
      "tensor(1007) -> )\n",
      "tensor(1016) -> 2\n",
      "tensor(1516) -> –\n",
      "tensor(2182) -> here\n",
      "tensor(11253) -> ##of\n",
      "tensor(2336) -> children\n",
      "tensor(2584) -> reached\n",
      "tensor(2083) -> through\n",
      "tensor(1996) -> the\n",
      "tensor(5278) -> changing\n",
      "tensor(14671) -> diabetes\n",
      "tensor(29656) -> ##®\n",
      "tensor(1999) -> in\n",
      "tensor(2336) -> children\n",
      "tensor(4746) -> programme\n",
      "tensor(1006) -> (\n",
      "tensor(23260) -> cumulative\n",
      "tensor(1007) -> )\n",
      "tensor(2111) -> people\n",
      "tensor(1004) -> &\n",
      "tensor(5126) -> employees\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1015) -> 1\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1015) -> 1\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1015) -> 1\n",
      "tensor(4029) -> 36\n",
      "tensor(1012) -> .\n",
      "tensor(1017) -> 3\n",
      "tensor(1015) -> 1\n",
      "tensor(1012) -> .\n",
      "tensor(1022) -> 8\n",
      "tensor(4601) -> 41\n",
      "tensor(1010) -> ,\n",
      "tensor(6021) -> 03\n",
      "tensor(2509) -> ##3\n",
      "tensor(4090) -> 34\n",
      "tensor(1012) -> .\n",
      "tensor(1020) -> 6\n",
      "tensor(1015) -> 1\n",
      "tensor(1012) -> .\n",
      "tensor(1021) -> 7\n",
      "tensor(2861) -> 31\n",
      "tensor(1010) -> ,\n",
      "tensor(6391) -> 84\n",
      "tensor(2575) -> ##6\n",
      "tensor(5126) -> employees\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1016) -> 2\n",
      "tensor(4583) -> 55\n",
      "tensor(1010) -> ,\n",
      "tensor(15376) -> 185\n",
      "tensor(4466) -> 48\n",
      "tensor(1010) -> ,\n",
      "tensor(4700) -> 47\n",
      "tensor(2620) -> ##8\n",
      "tensor(7904) -> employee\n",
      "tensor(20991) -> turnover\n",
      "tensor(9084) -> sustainable\n",
      "tensor(11194) -> employer\n",
      "tensor(3556) -> score\n",
      "tensor(2509) -> ##3\n",
      "tensor(6075) -> frequency\n",
      "tensor(1997) -> of\n",
      "tensor(16928) -> occupational\n",
      "tensor(13436) -> accidents\n",
      "tensor(1006) -> (\n",
      "tensor(2193) -> number\n",
      "tensor(2566) -> per\n",
      "tensor(2454) -> million\n",
      "tensor(2551) -> working\n",
      "tensor(2847) -> hours\n",
      "tensor(1007) -> )\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1016) -> 2\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1017) -> 3\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1018) -> 4\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1016) -> 2\n",
      "tensor(1003) -> %\n",
      "tensor(5594) -> 85\n",
      "tensor(1003) -> %\n",
      "tensor(1015) -> 1\n",
      "tensor(1012) -> .\n",
      "tensor(1019) -> 5\n",
      "tensor(2340) -> 11\n",
      "tensor(1012) -> .\n",
      "tensor(1014) -> 0\n",
      "tensor(1003) -> %\n",
      "tensor(6391) -> 84\n",
      "tensor(1003) -> %\n",
      "tensor(1015) -> 1\n",
      "tensor(1012) -> .\n",
      "tensor(1017) -> 3\n",
      "tensor(5907) -> gender\n",
      "tensor(1999) -> in\n",
      "tensor(4105) -> leadership\n",
      "tensor(4460) -> positions\n",
      "tensor(1006) -> (\n",
      "tensor(6463) -> ratio\n",
      "tensor(2273) -> men\n",
      "tensor(1024) -> :\n",
      "tensor(2308) -> women\n",
      "tensor(1007) -> )\n",
      "tensor(1022) -> 8\n",
      "tensor(1012) -> .\n",
      "tensor(1019) -> 5\n",
      "tensor(5179) -> 56\n",
      "tensor(1024) -> :\n",
      "tensor(4008) -> 44\n",
      "tensor(5401) -> 57\n",
      "tensor(1024) -> :\n",
      "tensor(4724) -> 43\n",
      "tensor(102) -> [SEP]\n"
     ]
    }
   ],
   "source": [
    "show_tokens(sentence=content[251], tokenizer=default_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe2b5cd-c6fb-42c7-b292-bfbce1e3a227",
   "metadata": {},
   "source": [
    "### Component 2 - Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aea0132a-3781-41a3-876b-48bdb0cd464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    # First element of model_output contains all token embeddings\n",
    "    token_embeddings = model_output[0]  \n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61ca7b44-bbe8-415e-9e89-6670a796ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLS Pooling - Take output from first token\n",
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245cdade-d18f-48ab-b246-6e31453fc0d9",
   "metadata": {},
   "source": [
    "<img src=\"pix/pooling.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d93f5e15-de41-4d71-8af4-9565c11e726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_device(batch, target_device: device):\n",
    "    \"\"\"\n",
    "    send a pytorch batch to a device (CPU/GPU)\n",
    "    \"\"\"\n",
    "    for key in batch:\n",
    "        if isinstance(batch[key], Tensor):\n",
    "            batch[key] = batch[key].to(target_device)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdadd8fe-cef5-4c15-a648-85ccc3ce5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batched_embeddings(sentences: List[str], batch_size: int, tokenizer, model, device=\"cpu\"):\n",
    "    \n",
    "    all_embeddings = []\n",
    "    once = False\n",
    "    \n",
    "    for start_index in trange(0, len(sentences), batch_size):\n",
    "        # 1. Tokenize sentences\n",
    "        batch = sentences[start_index:start_index+batch_size]\n",
    "        encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "        \n",
    "        encoded_input = batch_to_device(encoded_input, device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # 2. Compute token embeddings -> Same toke might have different embeddings due to context.\n",
    "            model_output = model(**encoded_input)\n",
    "\n",
    "            if once is False:\n",
    "                print(\"Shape of embedded tokens:\", model_output.last_hidden_state.shape)\n",
    "                once = True\n",
    "\n",
    "            # 3. Perform pooling\n",
    "            # Option 1: Mean pooling\n",
    "            # embeddings = mean_pooling(model_output, encoded_input.attention_mask)\n",
    "            \n",
    "            # Option 2: CLS pooling\n",
    "            embeddings = cls_pooling(model_output)\n",
    "            \n",
    "            embeddings = embeddings.detach()\n",
    "            all_embeddings.extend(embeddings)\n",
    "    \n",
    "    all_embeddings = torch.stack(all_embeddings)\n",
    "    \n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37dbf3fd-45c1-404b-b125-70cb4f4dc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_model = AutoModel.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-tas-b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d5193ac-80c4-4c4f-b950-dd28b25fd617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedded tokens: torch.Size([1, 375, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batched_embeddings = get_batched_embeddings(\n",
    "    sentences=[content[251]],\n",
    "    batch_size=1,\n",
    "    tokenizer=default_tokenizer,\n",
    "    model=default_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff9a208c-4a76-4377-abe4-00a4099f3c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0370e13-c27d-4a0a-96d0-71071120760e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2132133 ,  0.11719614,  0.22745958, -0.29696494,  0.16332254,\n",
       "        0.4249692 ,  0.2892638 , -0.5250201 ,  0.04183745, -0.41405323],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_embeddings[0].numpy()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b114f31f-eb1c-4832-b431-971f230c1ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.00]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.cos_sim(encoded_content, batched_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac8e2c-af8e-466a-b915-1a4ce13c8204",
   "metadata": {},
   "source": [
    "<div style=\"background-color: honeydew\">\n",
    "\n",
    "### The factors influence embeddings:\n",
    "- batch_size\n",
    "- pooling method\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d24eda-6150-41ff-92bb-d99b937e7c0e",
   "metadata": {},
   "source": [
    "## Search in embedded space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86d584f9-345a-43e7-8a44-54ccdfa3dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_query = \"what are scope 1 emissions?\"\n",
    "encoded_query = default_embedder.encode(default_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87af9135-c35c-44ad-803a-dc363f59ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs = default_embedder.encode(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecc305bf-83ab-4a3f-b5ac-32c1c6dc40ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_similarity(k, encoded_query, encoded_docs, is_cos_sim, debug):\n",
    "\n",
    "    if is_cos_sim:\n",
    "        # Compute cosine similarity between query and all document embeddings\n",
    "        cos_sim = util.cos_sim(encoded_query, encoded_docs)\n",
    "        \n",
    "        # Combine docs & scores\n",
    "        doc_idx_score_pairs = list(zip(range(len(encoded_docs)), cos_sim[0].tolist()))  # The first query\n",
    "\n",
    "    else:\n",
    "        # Compute dot score between query and all document embeddings\n",
    "        scores = util.dot_score(encoded_query, encoded_docs)[0].tolist()\n",
    "\n",
    "        # Combine docs & scores\n",
    "        doc_idx_score_pairs = list(zip(range(len(encoded_docs)), scores))\n",
    "    \n",
    "    # Sort by decreasing score\n",
    "    doc_idx_score_pairs = sorted(doc_idx_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Most similar pairs:\\ndoc_idx\\t score\")\n",
    "        for doc_idx, score in doc_idx_score_pairs[:k]:\n",
    "            print(f\"{doc_idx} \\t {score:.4f}\")\n",
    "    else:\n",
    "        return doc_idx_score_pairs[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "053a889f-9542-4ec5-9c8c-c5a2f1df8375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar pairs:\n",
      "doc_idx\t score\n",
      "260 \t 0.8382\n",
      "262 \t 0.8159\n",
      "261 \t 0.8079\n",
      "259 \t 0.7817\n",
      "19 \t 0.7793\n",
      "265 \t 0.7757\n",
      "23 \t 0.7705\n",
      "22 \t 0.7657\n",
      "21 \t 0.7652\n",
      "266 \t 0.7557\n"
     ]
    }
   ],
   "source": [
    "get_topk_similarity(\n",
    "    k=10, \n",
    "    encoded_query=encoded_query, \n",
    "    encoded_docs=encoded_docs, \n",
    "    is_cos_sim=True,\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07a9db8e-5bf9-4c39-b64a-8c54239f7537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar pairs:\n",
      "doc_idx\t score\n",
      "260 \t 103.9198\n",
      "261 \t 102.3122\n",
      "21 \t 101.1397\n",
      "262 \t 100.4351\n",
      "259 \t 100.2170\n",
      "20 \t 98.4837\n",
      "23 \t 98.0990\n",
      "19 \t 97.9896\n",
      "22 \t 97.5419\n",
      "265 \t 95.7639\n"
     ]
    }
   ],
   "source": [
    "get_topk_similarity(\n",
    "    k=10, \n",
    "    encoded_query=encoded_query, \n",
    "    encoded_docs=encoded_docs, \n",
    "    is_cos_sim=False,\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1235f632-47e9-4226-a44d-8fbd26c419ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Company: novo_nordisk. emissions from transportation, as supply chain constraints\\n\\nGSK, Merck KGaA, Roche, Sanofi, as well as the\\n\\nhave forced us to increase our use of airfreight to ensure\\n\\nWorld Health Organization (WHO), UNICEF, NHS\\n\\nEmissions from operations and transportation (1,000 tonnes CO2) Target 2030: zero emissions from operations and transportation\\n\\ntimely delivery of our medicines to patients globally. Due to\\n\\nour extensive supply chain, we have a target for all our 60,000+\\n\\nEngland and leading health research institutions.\\n\\nWhile initiated by HRH King Charles III in the UK, the\\n\\nsuppliers, to be reached by 2030, to source 100% renewable\\n\\npartnership is global in scope.\\n\\n350\\n\\n306\\n\\npower when supplying us. Already more than 500 of our key\\n\\n300\\n\\nsuppliers have committed to source renewable power, which\\n\\nBy agreeing on a set of concrete commitments and\\n\\n250\\n\\n200\\n\\n150\\n\\n170\\n\\n174\\n\\n218\\n\\nCompany cars (Scope 1)\\n\\nBusiness flights (Scope 3)\\n\\nhas resulted in a saving of more than 30,000 tonnes of CO2 since 2019 (equal to 1% of our emissions in 2022).\\n\\ninitiatives, launched ahead of COP27, the group\\n\\nseeks to harness its collective influence to urgently\\n\\naddress the need to make the healthcare sector\\n\\n100\\n\\nProduct distribution\\n\\nPartnerships will be an essential part of addressing the\\n\\nmore sustainable. This entails overall efforts towards\\n\\n50\\n\\n0\\n\\n(Scope 3)\\n\\nOffice buildings and\\n\\nlaboratories (Scope 1, 2)\\n\\nsupply chain challenge. In 2022, we made alliances with'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "741fa4de-344d-46e9-994a-c2aaefee9276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Company: novo_nordisk. 1. The calculation of Scope 3 emissions is substantially based on estimations\\n\\nand therefore inherently uncertain.\\n\\n2. Categories measured in CO2 equivalents (CO2e).\\n\\nProduction sites in France, Brazil, China, Iran and Algeria are located in areas subject to water stress or high seasonal variations (please refer to the CDP Water Security 2022 Reporting Guidance). They consume 13% of the total water for global production. Overall, water consumption at these facilities increased by 7% compared to 2021 due to an increase in production volumes. Implementation of water conservation projects in water-stressed areas led to savings of 6 thousand cubic meters of water.\\n\\nAccounting policies Water consumption is measured based on meter readings and invoices. It includes drinking water, industrial water and steam water used at production sites.\\n\\nAccounting policies Scope 1 and 2 emissions are limited to CO2 emissions from energy and do not include other greenhouse gases.\\n\\nCO2 emissions from operations (production, office buildings and laboratories) CO2 emissions from operations cover consumption of power, fuel, heat and steam at office buildings in Denmark, global production sites and laboratories and consumption of power in office buildings outside Denmark. Market-based emissions are calculated based on emission factors from the previous year.\\n\\n91\\n\\n2020\\n\\n75\\n\\n28\\n\\n2\\n\\n45\\n\\n15\\n\\n9\\n\\n6\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\nN/A\\n\\nN/A'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[261]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf68fc4-e3bf-4c22-bdb4-f7e977892b69",
   "metadata": {},
   "source": [
    "## What is the score for the correct answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2f6ed00-96f8-4071-9b58-9e4daafb582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pairs = get_topk_similarity(\n",
    "    k=100, \n",
    "    encoded_query=encoded_query, \n",
    "    encoded_docs=encoded_docs, \n",
    "    is_cos_sim=True,\n",
    "    debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b488766-8f80-4138-b9fc-a646b862e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_pair = [(ranking, result_pair) for (ranking, result_pair) in enumerate(result_pairs) if result_pair[0] == 251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f93b137a-d288-4815-8116-eb1482a4b7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17, (251, 0.7210701107978821))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0452a8-67e6-4029-9dbd-bd0d7956eddf",
   "metadata": {},
   "source": [
    "<div style=\"background-color: honeydew\">\n",
    "    \n",
    "### Why is the correct answer matchting almost all the exact words ranked so low?\n",
    "- The chunk is too long, thus it contains irrelevant content which interferes with its meaning and context?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74719808-fb94-407a-ab74-a277128b281c",
   "metadata": {},
   "source": [
    "## What are the other options?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd85516-363f-4930-a7f6-23f69cf1c61e",
   "metadata": {},
   "source": [
    "<img src=\"pix/tfidf.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b75a76d-c2ef-4a72-a6e9-8fa6f51ce926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize an instance of tf-idf vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Generate the tf-idf vectors for the docs\n",
    "content_matrix = tfidf_vectorizer.fit_transform(content)\n",
    "\n",
    "# Generate the tf-idf vectors for the query\n",
    "query_matrix = tfidf_vectorizer.transform([default_query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84400134-684b-4dba-a69c-ef3e4ad3dc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 5651)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f240f3d-4f11-43b9-8b4a-8fb1b15a552e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5651)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cea353cd-024a-4772-9a22-23e0577f003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_tfidf_similarity(k, encoded_query, encoded_docs, debug):\n",
    "\n",
    "    cos_sim = cosine_similarity(encoded_query, encoded_docs)\n",
    "\n",
    "    doc_idx_score_pairs = list(zip(range(content_matrix.shape[0]), cos_sim[0].tolist()))  # The first query\n",
    "    doc_idx_score_pairs = sorted(doc_idx_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Most similar pairs:\\ndoc_idx\\t score\")\n",
    "        for doc_idx, score in doc_idx_score_pairs[:k]:\n",
    "            print(f\"{doc_idx} \\t {score:.4f}\")\n",
    "    else:\n",
    "        return doc_idx_score_pairs[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8fce5896-d644-44bd-a689-773db7d47901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar pairs:\n",
      "doc_idx\t score\n",
      "22 \t 0.4045\n",
      "262 \t 0.3848\n",
      "260 \t 0.3026\n",
      "265 \t 0.2394\n",
      "19 \t 0.2335\n",
      "20 \t 0.2172\n",
      "21 \t 0.1979\n",
      "264 \t 0.1916\n",
      "263 \t 0.1858\n",
      "251 \t 0.1646\n"
     ]
    }
   ],
   "source": [
    "get_topk_tfidf_similarity(\n",
    "    k=10, \n",
    "    encoded_query=query_matrix, \n",
    "    encoded_docs=content_matrix,\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1e511-4f3e-4ac2-b7c1-a79fd8f8a312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-redis-demo",
   "language": "python",
   "name": "rag-redis-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
